---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# chap.r.sdk

<!-- badges: start -->
[![R-CMD-check](https://github.com/knutdrand/chap_r_sdk/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/knutdrand/chap_r_sdk/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

The CHAP R SDK provides tools for building disease forecasting models compatible with the [CHAP platform](https://github.com/dhis2/chap-core). It handles CLI creation, data loading, validation, and prediction format conversion.

## Installation

You can install the development version of chap.r.sdk from GitHub:

```r
# install.packages("remotes")
remotes::install_github("knutdrand/chap_r_sdk")
```

## Building Your First CHAP Model

This tutorial walks you through building a CHAP-compatible model step-by-step, using a validation-first approach.

### Setup

```{r setup}
library(chap.r.sdk)
library(dplyr)
```

### Step 1: Understand the Function Interface

Every CHAP model requires two functions:

**Training function:**
```r
train_fn <- function(training_data, model_configuration = list()) {
  # training_data: tsibble with time_period index, location key,
  #                disease_cases, and covariates
  # model_configuration: optional list of parameters
  # Returns: any model object (list, fitted model, etc.)
}
```

**Prediction function:**
```r
predict_fn <- function(historic_data, future_data, saved_model,
                       model_configuration = list()) {
  # historic_data: tsibble with historical observations
  # future_data: tsibble with time periods to predict
  # saved_model: the object returned by train_fn
  # Returns: tibble with samples list-column containing numeric vectors
  #   - For deterministic models: single sample per row (e.g., samples = list(c(42)))
  #   - For probabilistic models: multiple samples per row (e.g., 1000 samples)
  #
  # IMPORTANT: historic_data may contain more recent data than training_data.
  # For time series models, you should refit to historic_data before forecasting.
  # Use saved_model for hyperparameters/structure, not the fitted model itself.
  # See examples/arima_model/ for a demonstration of this pattern.
}
```

### Step 2: Explore the Example Data

The SDK provides example datasets for testing. Let's examine the Laos monthly data:

```{r explore-data}
data <- get_example_data('laos', 'M')
names(data)
```

The example data contains four tsibbles. Each has `time_period` as the index and `location` as the key:

**Training data** - what your model learns from:
```{r}
data$training_data
```

**Future data** - time periods to predict (no `disease_cases`):
```{r}
data$future_data
```

**Example predictions** - what your model should output:
```{r}
data$predictions
```

The predictions tibble has a `samples` list-column where each element is a numeric vector. Let's look at the structure:

```{r}
# Each row has a vector of samples
data$predictions$samples[[1]]
```

For probabilistic models, each vector contains multiple Monte Carlo samples (e.g., 1000). For deterministic models, use a single sample per row: `samples = list(c(42))`.

### Step 3: Validate Before Implementing

Before writing any model logic, let's see what the validation expects. Start with stub functions:

```{r validate-stubs}
train_fn <- function(training_data, model_configuration = list()) {
  list(dummy = 1)
}

predict_fn <- function(historic_data, future_data, saved_model,
                       model_configuration = list()) {
  future_data
}

result <- validate_model_io(train_fn, predict_fn, data)
result$success
result$errors
```

The validation tells us exactly what's missing: the `samples` list-column in predictions.

### Step 4: Implement a Simple Mean Model

Now let's implement a minimal model that predicts the historical mean for each location.
Since all models must return a `samples` list-column, we wrap the single prediction value in a list:

```{r implement-model}
train_fn <- function(training_data, model_configuration = list()) {
  means <- training_data |>
    as_tibble() |>
    summarise(mean_cases = mean(disease_cases, na.rm = TRUE), .by = location)
  list(means = means)
}

predict_fn <- function(historic_data, future_data, saved_model,
                       model_configuration = list()) {
  future_data |>
    left_join(saved_model$means, by = "location") |>
    mutate(samples = purrr::map(mean_cases, ~c(.x))) |>
    select(-mean_cases)
}
```

Note: We use `as_tibble()` in the training function because `summarise(.by = ...)` needs a tibble to collapse across the time dimension.

### Step 5: Validate the Implementation

```{r validate-implementation}
result <- validate_model_io(train_fn, predict_fn, data)
result$success
result$n_predictions
```

### Step 6: Create the CLI

Once validation passes, wrap your model in a CLI. Create a file called `model.R`:

```r
library(chap.r.sdk)
library(dplyr)

train_fn <- function(training_data, model_configuration = list()) {
  means <- training_data |>
    as_tibble() |>
    summarise(mean_cases = mean(disease_cases, na.rm = TRUE), .by = location)
  list(means = means)
}

predict_fn <- function(historic_data, future_data, saved_model,
                       model_configuration = list()) {
  future_data |>
    left_join(saved_model$means, by = "location") |>
    mutate(samples = purrr::map(mean_cases, ~c(.x))) |>
    select(-mean_cases)
}

if (!interactive()) {
  create_chap_cli(train_fn, predict_fn)
}
```

**Usage:**
```bash
# Train the model
Rscript model.R train training_data.csv

# Generate predictions
Rscript model.R predict historic.csv future.csv model.rds

# Display model info
Rscript model.R info
```

The CLI automatically handles CSV loading, tsibble conversion, model saving, and prediction output.

## Probabilistic Models

For probabilistic forecasting, include multiple Monte Carlo samples:

```r
predict_fn <- function(historic_data, future_data, saved_model,
                       model_configuration = list()) {
  n_samples <- 1000

  future_data |>
    left_join(saved_model$means, by = "location") |>
    rowwise() |>
    mutate(
      samples = list(rpois(n_samples, lambda = mean_cases))
    ) |>
    ungroup() |>
    select(-mean_cases)
}
```

## Working with Samples

The SDK provides utility functions for sample-based predictions:

```r
# Convert nested samples to wide format
wide_preds <- predictions_to_wide(nested_preds)

# Convert to long format for scoringutils
long_preds <- predictions_to_long(nested_preds)

# Compute quantiles for hub submissions
quantile_preds <- predictions_to_quantiles(nested_preds)

# Add summary statistics (mean, median, CIs)
preds_with_summary <- predictions_summary(nested_preds)
```

## Learn More

- [Full documentation](https://knutdrand.github.io/chap_r_sdk/)
- [Model development tutorial](https://knutdrand.github.io/chap_r_sdk/articles/model-development-tutorial.html)
- [Function reference](https://knutdrand.github.io/chap_r_sdk/reference/index.html)
